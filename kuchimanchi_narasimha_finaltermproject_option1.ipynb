{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Option 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported libraries:\n",
    "* sklearn.preprocessing in order to use LabelEncoder to convert the labels into a binary representation\n",
    "* sklearn.preprocessing.MinMaxScaler to scale the features so that there is no bias when the model is weighting the features\n",
    "* sklearn.naive_bayes.GaussianNB to use the Gaussian Naive Bayes model on the data\n",
    "* sklearn.tree.DecisionTreeClassifier to use the Decision Tree model on the data\n",
    "* sklearn.model_selection.KFold to prerform ten-fold cross validation on the data and obtain a mean score on each model\n",
    "* numpy in order to use numpy arrays for efficient data manipulation\n",
    "* csv to read and write to csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiation of both the `LabelEncoder` and the `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below extracts the data from a .data, .csv or .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    with open(filename, \"rt\", encoding='utf8') as f:\n",
    "        file = csv.reader(f)\n",
    "        temp = list(file)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below writes a list or nested list to a .csv which will be used to export the features and labels for review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(filename, nested_list):\n",
    "    with open(filename, 'w', newline='\\n', encoding='utf-8'):\n",
    "        output_array = np.array(nested_list)\n",
    "        np.savetxt(filename, output_array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below clean the data by removing unknown data, represented as a `?`, with the mean of that feautre column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_with_mean(lists):\n",
    "    for nested_list in lists:\n",
    "        for i, item in enumerate(nested_list):\n",
    "            if item == '?':\n",
    "                nested_list[i] = np.NaN\n",
    "\n",
    "    means = np.nanmean(np.array(lists).astype(float), axis=0)\n",
    "\n",
    "    for nested_list in lists:\n",
    "        for y, item in enumerate(nested_list):\n",
    "            if math.isnan(float(item)):\n",
    "                nested_list[y] = means[y]\n",
    "\n",
    "    return(np.array(lists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below seperate the features and labels from the input data and returns both respective datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_features_and_labels(file):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for row in file:\n",
    "        features.append(row[2:])\n",
    "        labels.append(row[1])\n",
    "\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    features = scaler.fit_transform(clean_with_mean(features))\n",
    "\n",
    "    return(features, labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below performs ten fold cross validation by indexing the features and labels, randomly grouping the features and labels into sets of training and test data respectively. Because there are ten splits, the data is split into a 90 to 10 ratio of test and train respectively. A score is obtained by comparing the prediction of the model with the actual label associated with the features. The process is repeated ten times and a mean of the scores is calculated that represents the effectiveness of the model in predicting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_fold(model, features, labels):\n",
    "    scores = []\n",
    "    splits = 10\n",
    "    cv = KFold(n_splits=splits, random_state=1, shuffle=False)\n",
    "    for train_index, test_index in cv.split(features):\n",
    "        x_train, x_test, y_train, y_test = features[train_index], features[\n",
    "            test_index], labels[train_index], labels[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        scores.append(model.score(x_test, y_test))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is extracted from the .data file using the `get_data` function and seperated using the `seperate_features_and_labels` function. The features and labels are exported to csv files for review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-765b61a8c726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scar_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseperate_features_and_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Features: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Labels: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-70b48e63fce9>\u001b[0m in \u001b[0;36mseperate_features_and_labels\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabels_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_with_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-e8ff1c48e5ca>\u001b[0m in \u001b[0;36mclean_with_mean\u001b[1;34m(lists)\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mnested_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnested_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "data = get_data('scar_data.csv')\n",
    "features, labels = seperate_features_and_labels(data)\n",
    "print('Features: \\n', features.view())\n",
    "print('Labels: \\n', labels.view())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian Naive Bayes model is instantiated and is inputted into the `ten_fold` function along with the features and labels. The scores are returned and the mean of the scores is outputted for review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score of the Gaussian Naive Bayes Model for the data is 68.1%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scores = ten_fold(model, features, labels)\n",
    "nb_mean_score = \"{:.1%}\".format(np.mean(scores))\n",
    "print (f'The mean score of the Gaussian Naive Bayes Model for the data is {nb_mean_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
